{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sklearn as sk\n",
    "from sklearn import preprocessing\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.feature_selection import SelectKBest, chi2\n",
    "from sklearn import svm\n",
    "from sklearn import linear_model, dummy, metrics\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.metrics import *\n",
    "import time\n",
    "import os\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(r\"training.csv\", decimal = ',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Dropping variable 10, 17 and 19 as they are totally dependent on variable11 variable14 & ClassLabel respectively.\n",
    "#Dropping variable18 becasue of 60% missing values\n",
    "#Dropping variable3, 8 & 15' because of being outlier (high stdev)\n",
    "df = df.drop(columns=['variable3', 'variable8','variable10','variable15','variable17','variable18','variable19'])\n",
    "\n",
    "\n",
    "df = df.dropna() #Removing rows with Nan or NA values\n",
    "df['classLabel'].replace({'no.': 0, 'yes.': 1},inplace = True) #ClassLabel Column transformation\n",
    "\n",
    "#assuming that t means 'TRUE', and f indicates 'FALSE' in variable9, variable10, and variable12. t = 1, f = 0\n",
    "df['variable9'].replace({'f': 0, 't': 1},inplace = True)\n",
    "df['variable12'].replace({'f': 0, 't': 1},inplace = True)\n",
    "\n",
    "#cleaning rest of non-numeric variables\n",
    "categorical_columns = ['variable1','variable4', 'variable5', 'variable6', 'variable7', 'variable13']\n",
    "# transform the categorical columns\n",
    "df = pd.get_dummies(df, columns=categorical_columns)\n",
    "\n",
    "#Using MinMaxScaler to standardize our data\n",
    "scaler = preprocessing.MinMaxScaler()\n",
    "scaler.fit(df)\n",
    "df = pd.DataFrame(scaler.transform(df), index=df.index, columns=df.columns)\n",
    "\n",
    "#Declaring X and y variable\n",
    "X = df.loc[:,df.columns!='classLabel']\n",
    "y = df[['classLabel']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Decision Tree Classifier\n",
    "X_train,X_test,y_train,y_test = train_test_split(X,y,test_size=0.25)\n",
    "clf_dt = DecisionTreeClassifier(random_state=0) #logisticRegr\n",
    "clf_dt.fit(X_train,y_train)\n",
    "y_pred = clf_dt.predict(X_test) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Input File\n",
    "dfv = pd.read_csv(r\"validation.csv\", decimal = ',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Cleaning input File\n",
    "\n",
    "#Performing the same cleaning on this data as it was done on training + test data\n",
    "dfv = dfv.drop(columns=['variable18'])\n",
    "dfv = dfv.dropna()\n",
    "org_dfv_X = dfv #keeping a backup file for orginal data\n",
    "dfv = dfv.drop(columns=['variable3', 'variable8','variable10','variable15','variable17','variable19']) \n",
    "\n",
    "\n",
    "dfv['classLabel'].replace({'no.': 0, 'yes.': 1},inplace = True)\n",
    "dfv['variable9'].replace({'f': 0, 't': 1},inplace = True)\n",
    "dfv['variable12'].replace({'f': 0, 't': 1},inplace = True)\n",
    "\n",
    "\n",
    "categorical_columns = ['variable1','variable4', 'variable5', 'variable6', 'variable7', 'variable13']\n",
    "dfv = pd.get_dummies(dfv, columns=categorical_columns)\n",
    "\n",
    "\n",
    "scaler = preprocessing.MinMaxScaler()\n",
    "scaler.fit(dfv)\n",
    "dfv = pd.DataFrame(scaler.transform(dfv), index=dfv.index, columns=dfv.columns)\n",
    "\n",
    "#Converting this to transform it as trained model format\n",
    "df2 = df.iloc[0:0]\n",
    "df3 = pd.concat([df2,dfv], sort = False)\n",
    "df3 = df3.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Input X and y of validation dataset\n",
    "X_val = df3.loc[:,df3.columns!='classLabel']\n",
    "#y_val = df3[['classLabel']]\n",
    "y_predicted = clf_dt.predict(X_val)\n",
    "\n",
    "y_predicted_df = pd.DataFrame({'Predicted':y_predicted})\n",
    "y_predicted_df.replace({0: 'No', 1: 'Yes'},inplace = True)\n",
    "#y_val.reset_index(drop=True, inplace=True)\n",
    "org_dfv_X.reset_index(drop=True, inplace=True)\n",
    "result = pd.concat([org_dfv_X, y_predicted_df], axis=1)\n",
    "result.to_csv(r\"result.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#confusion_matrix(y_val, y_predicted)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
